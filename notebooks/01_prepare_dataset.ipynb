{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7edf8dd5",
   "metadata": {},
   "source": [
    "# 01_prepare_dataset.ipynb\n",
    "\n",
    "Prepare the **Facial Emotion Recognition** dataset for the Emotion Recognition CNN model I am building\n",
    "\n",
    "This notebook:\n",
    "1. Checks the environment and dependencies.\n",
    "2. Defines paths for the raw YOLO dataset and output folders.\n",
    "3. Validates class mapping for **9 emotions** (standardizes *Natural* → *Neutral*).\n",
    "4. Converts YOLO labels → **cropped grayscale face images** by class.\n",
    "5. Runs **basic quality checks** and summarizes class counts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b09d84",
   "metadata": {},
   "source": [
    "## Setup Environment and Paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b49642b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.13.9 (tags/v3.13.9:8183fa5, Oct 14 2025, 14:09:13) [MSC v.1944 64 bit (AMD64)]\n",
      "OS: Windows-11-10.0.26200-SP0\n",
      "NumPy: 2.2.6\n",
      "OpenCV: 4.11.0\n",
      "Matplotlib: 3.9.4\n",
      "YOLO root: C:\\Code\\Emotion-Recognition-CNN\\data\\raw_yolo\n",
      "Pool root: C:\\Code\\Emotion-Recognition-CNN\\data\\cls_pool\n",
      "Artifacts: C:\\Code\\Emotion-Recognition-CNN\\artifacts\\outputs\n"
     ]
    }
   ],
   "source": [
    "import sys, os, platform\n",
    "from pathlib import Path\n",
    "import numpy as np, cv2, matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"OS:\", platform.platform())\n",
    "print(\"NumPy:\", np.__version__)\n",
    "print(\"OpenCV:\", cv2.__version__)\n",
    "print(\"Matplotlib:\", matplotlib.__version__)\n",
    "\n",
    "DATA_ROOT = Path(\"../data\")\n",
    "YOLO_ROOT = DATA_ROOT / \"raw_yolo\"   # expected: train/ valid/ test/ each with images/ & labels/\n",
    "\n",
    "# Output folders\n",
    "POOL_ROOT = DATA_ROOT / \"cls_pool\"   # output: class-organized pool for Model Notebook\n",
    "ART_OUT = Path(\"../artifacts\") / \"outputs\"\n",
    "\n",
    "for p in [POOL_ROOT, ART_OUT]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"YOLO root:\", YOLO_ROOT.resolve())\n",
    "print(\"Pool root:\", POOL_ROOT.resolve())\n",
    "print(\"Artifacts:\", ART_OUT.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3120bf7",
   "metadata": {},
   "source": [
    "## Define Class map (9 emotions)\n",
    "\n",
    "Standardize “Natural” → **Neutral** for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "228d0845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Angry',\n",
       " 1: 'Contempt',\n",
       " 2: 'Disgust',\n",
       " 3: 'Fear',\n",
       " 4: 'Happy',\n",
       " 5: 'Neutral',\n",
       " 6: 'Sad',\n",
       " 7: 'Sleepy',\n",
       " 8: 'Surprised'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID2NAME = {\n",
    "    0: \"Angry\",\n",
    "    1: \"Contempt\",\n",
    "    2: \"Disgust\",\n",
    "    3: \"Fear\",\n",
    "    4: \"Happy\",\n",
    "    5: \"Neutral\",  # called \"Natural\" in source\n",
    "    6: \"Sad\",\n",
    "    7: \"Sleepy\",\n",
    "    8: \"Surprised\",\n",
    "}\n",
    "NAME2ID = {v:k for k,v in ID2NAME.items()}\n",
    "NUM_CLASSES = len(ID2NAME)\n",
    "ID2NAME\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54358f44",
   "metadata": {},
   "source": [
    "## Scan YOLO split structure\n",
    "\n",
    "Verify label files exist under each split:\n",
    "- `raw_yolo/train/labels/`\n",
    "- `raw_yolo/valid/labels/`\n",
    "- `raw_yolo/test/labels/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d1545a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: labels=64866 | labels dir: True | images dir: True\n",
      "valid: labels= 1720 | labels dir: True | images dir: True\n",
      "test : labels= 1700 | labels dir: True | images dir: True\n",
      "Total label files across splits: 68286\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "splits = [\"train\", \"valid\", \"test\"]\n",
    "label_index = {}\n",
    "total_lbl = 0\n",
    "\n",
    "for sp in splits:\n",
    "    lbl_dir = YOLO_ROOT / sp / \"labels\"\n",
    "    imgs_dir = YOLO_ROOT / sp / \"images\"\n",
    "    label_files = sorted(lbl_dir.glob(\"*.txt\")) if lbl_dir.exists() else []\n",
    "    label_index[sp] = (imgs_dir, label_files)\n",
    "    print(f\"{sp:5s}: labels={len(label_files):5d} | labels dir: {lbl_dir.exists()} | images dir: {imgs_dir.exists()}\")\n",
    "    total_lbl += len(label_files)\n",
    "\n",
    "print(\"Total label files across splits:\", total_lbl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4472d748",
   "metadata": {},
   "source": [
    "## Convert YOLO labels (across all splits) → unified class pool\n",
    "\n",
    "For each `*.txt`:\n",
    "1) read lines: `class x_center y_center width height` (normalized 0..1)  \n",
    "2) find paired image (same stem under that split's `images/`)  \n",
    "3) crop with a small margin (~8%), convert to **grayscale**  \n",
    "4) dedupe by **SHA1 hash of the grayscale crop** (skips exact duplicates across splits)  \n",
    "5) save to: `data/cls_pool/<ClassName>/<stem>_<hash7>.jpg`  \n",
    "6) record a manifest entry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfb84465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 67915 unique crops into pool. Skipped 366 duplicates.\n"
     ]
    }
   ],
   "source": [
    "import hashlib, json, cv2\n",
    "from pathlib import Path\n",
    "\n",
    "SUPPORTED_EXTS = (\".jpg\", \".png\", \".jpeg\", \".JPG\", \".PNG\", \".JPEG\")\n",
    "\n",
    "def _clip(v, lo, hi): return max(lo, min(hi, v))\n",
    "\n",
    "def find_image(imgs_dir: Path, stem: str):\n",
    "    for ext in SUPPORTED_EXTS:\n",
    "        p = imgs_dir / f\"{stem}{ext}\"\n",
    "        if p.exists():\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "manifest = {\n",
    "    \"source\": str(YOLO_ROOT.resolve()),\n",
    "    \"pool_root\": str(POOL_ROOT.resolve()),\n",
    "    \"files\": [],                  # entries: {split, src_img, src_lbl, dst, class, sha1}\n",
    "    \"duplicates_skipped\": 0,\n",
    "    \"unknown_classes\": []\n",
    "}\n",
    "\n",
    "seen_hashes = set()\n",
    "saved = 0\n",
    "unknown_class_ids = set()\n",
    "\n",
    "for sp in splits:\n",
    "    imgs_dir, label_files = label_index[sp]\n",
    "    if not label_files: \n",
    "        continue\n",
    "\n",
    "    for lbl in label_files:\n",
    "        stem = lbl.stem\n",
    "        img_path = find_image(imgs_dir, stem)\n",
    "        if img_path is None:\n",
    "            continue\n",
    "\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        H, W = img.shape[:2]\n",
    "\n",
    "        with lbl.open(\"r\") as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) != 5:\n",
    "                    continue\n",
    "                cid, xc, yc, w, h = parts\n",
    "                try:\n",
    "                    cid = int(cid)\n",
    "                    xc, yc, w, h = map(float, (xc, yc, w, h))\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                if cid not in ID2NAME:\n",
    "                    unknown_class_ids.add(cid)\n",
    "                    continue\n",
    "\n",
    "                x1 = int((xc - w/2) * W); y1 = int((yc - h/2) * H)\n",
    "                x2 = int((xc + w/2) * W); y2 = int((yc + h/2) * H)\n",
    "\n",
    "                # add ~8% margin\n",
    "                mx = int(0.08 * (x2 - x1 + 1))\n",
    "                my = int(0.08 * (y2 - y1 + 1))\n",
    "                x1 = _clip(x1 - mx, 0, W-1); y1 = _clip(y1 - my, 0, H-1)\n",
    "                x2 = _clip(x2 + mx, 0, W-1); y2 = _clip(y2 + my, 0, H-1)\n",
    "\n",
    "                crop = img[y1:y2, x1:x2]\n",
    "                if crop.size == 0:\n",
    "                    continue\n",
    "\n",
    "                # grayscale\n",
    "                gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # stable hash of the crop (PNG-encoded bytes)\n",
    "                ok, buf = cv2.imencode(\".png\", gray)\n",
    "                if not ok:\n",
    "                    continue\n",
    "                sha = hashlib.sha1(buf.tobytes()).hexdigest()\n",
    "                if sha in seen_hashes:\n",
    "                    manifest[\"duplicates_skipped\"] += 1\n",
    "                    continue\n",
    "                seen_hashes.add(sha)\n",
    "\n",
    "                cls_name = ID2NAME[cid]\n",
    "                dst_dir = POOL_ROOT / cls_name\n",
    "                dst_dir.mkdir(parents=True, exist_ok=True)\n",
    "                dst = dst_dir / f\"{stem}_{sha[:7]}.jpg\"\n",
    "\n",
    "                cv2.imwrite(str(dst), gray)\n",
    "                manifest[\"files\"].append({\n",
    "                    \"split\": sp,\n",
    "                    \"src_img\": str(img_path.resolve()),\n",
    "                    \"src_lbl\": str(lbl.resolve()),\n",
    "                    \"dst\": str(dst.resolve()),\n",
    "                    \"class\": cls_name,\n",
    "                    \"sha1\": sha\n",
    "                })\n",
    "                saved += 1\n",
    "\n",
    "print(f\"Saved {saved} unique crops into pool. Skipped {manifest['duplicates_skipped']} duplicates.\")\n",
    "if unknown_class_ids:\n",
    "    manifest[\"unknown_classes\"] = sorted(int(x) for x in unknown_class_ids)\n",
    "    print(\"Warning: unknown class IDs encountered:\", sorted(unknown_class_ids))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d93510",
   "metadata": {},
   "source": [
    "## Pool summary & manifests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5046406f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Code\\Emotion-Recognition-CNN\\artifacts\\outputs\\class_names.json\n",
      "Saved: C:\\Code\\Emotion-Recognition-CNN\\artifacts\\outputs\\pool_summary.json\n",
      "Saved: C:\\Code\\Emotion-Recognition-CNN\\artifacts\\outputs\\pool_manifest.json\n",
      "Angry        : 11699\n",
      "Contempt     : 2693\n",
      "Disgust      : 4502\n",
      "Fear         : 5424\n",
      "Happy        : 14582\n",
      "Neutral      : 5966\n",
      "Sad          : 12545\n",
      "Sleepy       : 1120\n",
      "Surprised    : 9384\n",
      "Total in pool: 67915\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "# summarize counts in pool\n",
    "pool_counts = Counter()\n",
    "for ext in (\".jpg\", \".jpeg\", \".png\"):\n",
    "    pool_counts += Counter(p.parent.name for p in POOL_ROOT.rglob(f\"*{ext}\"))\n",
    "\n",
    "summary = {\n",
    "    \"pool_root\": str(POOL_ROOT.resolve()),\n",
    "    \"counts\": dict(pool_counts),\n",
    "    \"total\": int(sum(pool_counts.values()))\n",
    "}\n",
    "\n",
    "# write artifacts\n",
    "with open(ART_OUT / \"class_names.json\", \"w\") as f:\n",
    "    json.dump(list(ID2NAME.values()), f, indent=2)\n",
    "\n",
    "with open(ART_OUT / \"pool_summary.json\", \"w\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "with open(ART_OUT / \"pool_manifest.json\", \"w\") as f:\n",
    "    json.dump(manifest, f, indent=2)\n",
    "\n",
    "print(\"Saved:\", (ART_OUT / \"class_names.json\").resolve())\n",
    "print(\"Saved:\", (ART_OUT / \"pool_summary.json\").resolve())\n",
    "print(\"Saved:\", (ART_OUT / \"pool_manifest.json\").resolve())\n",
    "\n",
    "for cls in sorted(pool_counts):\n",
    "    print(f\"{cls:12s} : {pool_counts[cls]}\")\n",
    "print(\"Total in pool:\", summary[\"total\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (EmotionRecognitionCNN)",
   "language": "python",
   "name": "emotionrecognitioncnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
